"""
Life Science Keyword Clustering & Research Area Recommendation Pipeline
=======================================================================
Input:  A plain .txt or .csv file with one keyword per line (or a 'keyword' column)
Output:
  - clusters.csv         â€” every keyword with its research area + sub-topic cluster
  - recommendations.csv  â€” ranked research areas with opportunity scores
  - report.html          â€” visual summary with interactive scatter plot

How it works:
  1. Embed all keywords semantically (free local model, no API key)
  2. Map EVERY keyword to a predefined life science research area taxonomy
     using cosine similarity â€” output is always "Cancer", "Neurology" etc.
  3. Cluster into sub-topics within those areas (surfaces themes like
     "HER2 breast cancer" or "KRAS lung cancer" within Oncology)
  4. Score and rank research areas by keyword coverage + similarity strength
  5. MeSH is NOT used as the source of area names (that was the bug)

Dependencies (all free / open-source):
    pip install sentence-transformers scikit-learn pandas numpy plotly

Usage:
    python lifesci_keyword_pipeline.py --input keywords.txt
    python lifesci_keyword_pipeline.py --input keywords.csv --col keyword --output ./results
"""

import argparse
import os
import warnings
import numpy as np
import pandas as pd

warnings.filterwarnings("ignore")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESEARCH AREA TAXONOMY
# Each area has a rich description used for semantic matching.
# To add a new area, just append a dict to this list.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RESEARCH_AREAS = [
    {
        "name": "Oncology / Cancer",
        "description": (
            "cancer tumor oncology malignancy carcinoma lymphoma leukemia melanoma "
            "sarcoma metastasis chemotherapy immunotherapy targeted therapy "
            "CAR-T cell therapy checkpoint inhibitor tumor microenvironment "
            "solid tumor hematologic malignancy breast cancer lung cancer "
            "colorectal cancer prostate cancer ovarian cancer pancreatic cancer "
            "glioblastoma biomarker tumor suppressor oncogene KRAS EGFR HER2 PD-1 PD-L1"
        ),
    },
    {
        "name": "Neurology / Neuroscience",
        "description": (
            "neurology neuroscience brain neuron synapse neurodegeneration "
            "Alzheimer Parkinson multiple sclerosis ALS epilepsy stroke "
            "dementia cognitive decline neuropathy blood brain barrier "
            "glia astrocyte microglia neuroinflammation CNS psychiatric "
            "depression anxiety schizophrenia ADHD autism brain tumor spinal cord"
        ),
    },
    {
        "name": "Cardiovascular Disease",
        "description": (
            "cardiovascular heart cardiac coronary artery disease myocardial infarction "
            "heart failure atrial fibrillation hypertension atherosclerosis "
            "stroke vascular endothelium lipid cholesterol thrombosis "
            "anticoagulant platelet troponin BNP cardiomyopathy arrhythmia "
            "valve aorta peripheral arterial PCSK9 statin"
        ),
    },
    {
        "name": "Immunology / Inflammation",
        "description": (
            "immunology immune system inflammation autoimmune allergy "
            "cytokine T cell B cell antibody innate adaptive immunity "
            "rheumatoid arthritis lupus inflammatory bowel disease Crohn "
            "complement macrophage neutrophil interleukin TNF interferon "
            "mast cell dendritic cell regulatory T cell Treg immunosuppression "
            "vaccine adjuvant antigen MHC HLA toll-like receptor"
        ),
    },
    {
        "name": "Infectious Disease / Microbiology",
        "description": (
            "infectious disease infection bacteria virus pathogen antimicrobial "
            "antibiotic resistance HIV AIDS influenza SARS-CoV-2 COVID-19 "
            "tuberculosis malaria fungal parasitic sepsis bacteremia "
            "microbiome gut flora pathogenesis virulence host defense "
            "vaccine antiviral antifungal epidemiology outbreak zoonotic RSV"
        ),
    },
    {
        "name": "Genomics / Genetics",
        "description": (
            "genomics genetics gene mutation variant sequencing DNA RNA "
            "CRISPR gene editing genome-wide association GWAS exome "
            "next-generation sequencing NGS single nucleotide polymorphism SNP "
            "epigenetics methylation chromatin histone gene expression "
            "transcriptomics RNA-seq mRNA non-coding RNA microRNA lncRNA "
            "copy number variant chromosomal rearrangement hereditary inheritance"
        ),
    },
    {
        "name": "Cell Biology / Molecular Biology",
        "description": (
            "cell biology molecular biology cell signaling pathway "
            "apoptosis autophagy cell cycle proliferation differentiation "
            "stem cell organoid protein complex enzyme kinase phosphorylation "
            "receptor ligand transcription factor Western blot immunoprecipitation "
            "flow cytometry microscopy CRISPR knockout knockdown overexpression "
            "plasmid transfection cell line culture co-immunoprecipitation"
        ),
    },
    {
        "name": "Metabolic Disease / Endocrinology",
        "description": (
            "metabolic disease diabetes obesity insulin resistance type 2 diabetes "
            "type 1 diabetes glucose lipid metabolism fatty liver NASH NAFLD "
            "thyroid adrenal pituitary hormone endocrine metabolic syndrome "
            "dyslipidemia hyperglycemia glycemic control bariatric surgery "
            "GLP-1 SGLT2 metformin adipose tissue adipokine leptin ghrelin"
        ),
    },
    {
        "name": "Respiratory / Pulmonary Disease",
        "description": (
            "respiratory pulmonary lung COPD asthma cystic fibrosis "
            "interstitial lung disease pulmonary fibrosis pneumonia "
            "ARDS ventilation bronchitis emphysema sleep apnea "
            "inhaler bronchodilator corticosteroid airway inflammation "
            "surfactant alveolar oxygen saturation spirometry FEV1"
        ),
    },
    {
        "name": "Rare Disease / Orphan Disease",
        "description": (
            "rare disease orphan disease genetic disorder enzyme deficiency "
            "lysosomal storage disease muscular dystrophy Duchenne Becker "
            "Huntington disease hemophilia sickle cell phenylketonuria PKU "
            "Fabry Gaucher Pompe Wilson disease gene therapy enzyme replacement "
            "newborn screening ultra-rare pediatric unmet medical need"
        ),
    },
    {
        "name": "Drug Discovery / Pharmacology",
        "description": (
            "drug discovery pharmacology small molecule compound library "
            "high throughput screening HTS lead optimization ADMET "
            "pharmacokinetics pharmacodynamics IC50 EC50 binding affinity "
            "target engagement selectivity medicinal chemistry structure activity "
            "clinical trial phase I II III FDA approval IND NDA drug candidate "
            "in vitro in vivo preclinical toxicology"
        ),
    },
    {
        "name": "Biologics / Antibody Therapeutics",
        "description": (
            "biologics antibody monoclonal antibody bispecific antibody "
            "ADC antibody drug conjugate biosimilar protein therapeutic "
            "Fc region glycosylation CHO cell expression system "
            "bioreactor upstream downstream purification formulation "
            "immunogenicity subcutaneous intravenous half-life Fc fusion "
            "nanobody VHH single domain antibody"
        ),
    },
    {
        "name": "Diagnostics / Biomarkers",
        "description": (
            "diagnostic biomarker assay test ELISA immunoassay PCR qPCR "
            "liquid biopsy circulating tumor DNA ctDNA cfDNA proteomics "
            "mass spectrometry metabolomics point of care lateral flow "
            "sensitivity specificity ROC AUC clinical validation "
            "companion diagnostic IVD laboratory test biopsy pathology"
        ),
    },
    {
        "name": "Dermatology / Skin Disease",
        "description": (
            "dermatology skin psoriasis eczema atopic dermatitis acne "
            "melanoma basal cell carcinoma squamous cell carcinoma "
            "wound healing scar fibrosis collagen elastin keratinocyte "
            "transdermal topical retinoid biologic alopecia vitiligo rosacea"
        ),
    },
    {
        "name": "Gastroenterology / Hepatology",
        "description": (
            "gastroenterology hepatology liver gut intestine colon "
            "inflammatory bowel disease IBD Crohn colitis celiac "
            "hepatitis cirrhosis non-alcoholic fatty liver NASH fibrosis "
            "microbiome gastrointestinal motility pancreas bile acid "
            "endoscopy colonoscopy H pylori GI bleeding portal hypertension"
        ),
    },
    {
        "name": "Musculoskeletal / Bone Disease",
        "description": (
            "musculoskeletal bone joint muscle osteoporosis osteoarthritis "
            "rheumatoid arthritis fracture cartilage tendon ligament "
            "spine intervertebral disc osteoblast osteoclast bone density "
            "DEXA scan bisphosphonate RANKL denosumab physical therapy"
        ),
    },
    {
        "name": "Ophthalmology / Eye Disease",
        "description": (
            "ophthalmology eye retina macular degeneration AMD glaucoma "
            "diabetic retinopathy cataract cornea intraocular pressure "
            "anti-VEGF intravitreal injection vitreous photoreceptor "
            "optic nerve visual acuity OCT fluorescein angiography"
        ),
    },
    {
        "name": "Hematology / Blood Disease",
        "description": (
            "hematology blood anemia sickle cell hemophilia thrombocytopenia "
            "myeloma lymphoma leukemia bone marrow transplant stem cell "
            "erythrocyte platelet coagulation von Willebrand factor "
            "iron deficiency thalassemia myelodysplastic syndrome MDS CLL AML"
        ),
    },
    {
        "name": "Renal / Kidney Disease",
        "description": (
            "renal kidney nephrology chronic kidney disease CKD acute kidney "
            "injury dialysis transplant glomerulonephritis proteinuria "
            "creatinine GFR RAAS ACE inhibitor podocyte fibrosis "
            "polycystic kidney disease PKD IgA nephropathy"
        ),
    },
    {
        "name": "Reproductive Medicine / Women's Health",
        "description": (
            "reproductive medicine fertility IVF endometriosis PCOS "
            "menopause contraception pregnancy maternal fetal obstetrics "
            "cervical cancer ovarian cancer uterus endometrium hormone "
            "estrogen progesterone FSH LH prenatal preeclampsia"
        ),
    },
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 0. CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def parse_args():
    parser = argparse.ArgumentParser(description="Life Science Keyword â†’ Research Area Pipeline")
    parser.add_argument("--input",  required=True, help="Path to keyword file (.txt or .csv)")
    parser.add_argument("--col",    default="keyword", help="Column name if CSV (default: 'keyword')")
    parser.add_argument("--output", default="./output", help="Output directory (default: ./output)")
    parser.add_argument("--min-cluster-size", type=int, default=3,
                        help="Min keywords per sub-topic cluster (default: 3)")
    parser.add_argument("--top-n", type=int, default=20,
                        help="Top N research areas to surface (default: 20)")
    parser.add_argument("--threshold", type=float, default=0.20,
                        help="Min cosine similarity to classify a keyword (default: 0.20)")
    return parser.parse_args()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. LOAD KEYWORDS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_keywords(path: str, col: str) -> pd.DataFrame:
    print(f"\n[1/5] Loading keywords from: {path}")
    ext = os.path.splitext(path)[1].lower()
    if ext == ".txt":
        with open(path, "r", encoding="utf-8") as f:
            keywords = [line.strip() for line in f if line.strip()]
        df = pd.DataFrame({"keyword": keywords})
    elif ext == ".csv":
        df = pd.read_csv(path)
        if col not in df.columns:
            raise ValueError(f"Column '{col}' not found. Available: {list(df.columns)}")
        df = df.rename(columns={col: "keyword"})
        df = df[df["keyword"].notna()].reset_index(drop=True)
    else:
        raise ValueError("Input must be .txt or .csv")

    df["keyword"] = df["keyword"].str.strip().str.lower()
    df = df.drop_duplicates(subset="keyword").reset_index(drop=True)
    print(f"    â†’ {len(df)} unique keywords loaded")
    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. EMBED KEYWORDS + TAXONOMY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def embed_all(df: pd.DataFrame):
    """
    Embed keywords AND research area descriptions in the same vector space
    so cosine similarity between them is meaningful.
    """
    print("\n[2/5] Generating embeddings...")
    try:
        from sentence_transformers import SentenceTransformer
    except ImportError:
        raise ImportError("Run: pip install sentence-transformers")

    model = SentenceTransformer("all-MiniLM-L6-v2")

    print("      Embedding keywords...")
    kw_emb = model.encode(
        df["keyword"].tolist(),
        show_progress_bar=True,
        batch_size=64,
        normalize_embeddings=True
    )

    print("      Embedding research area taxonomy...")
    area_emb = model.encode(
        [a["description"] for a in RESEARCH_AREAS],
        show_progress_bar=False,
        normalize_embeddings=True
    )

    print(f"    â†’ Keywords: {kw_emb.shape} | Areas: {area_emb.shape}")
    return kw_emb, area_emb


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. MAP KEYWORDS â†’ RESEARCH AREAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def map_to_research_areas(df: pd.DataFrame, kw_emb: np.ndarray,
                           area_emb: np.ndarray, threshold: float) -> pd.DataFrame:
    """
    Compute cosine similarity between every keyword and every research area.
    Assign each keyword to its best-matching area.
    Keywords below threshold â†’ "Unclassified / General Methods"
    """
    print(f"\n[3/5] Mapping keywords to research areas (threshold={threshold})...")

    # (n_keywords, n_areas) â€” dot product of normalized vectors = cosine similarity
    sim = kw_emb @ area_emb.T

    best_idx    = sim.argmax(axis=1)
    best_score  = sim.max(axis=1)

    # Second best (useful for cross-cutting keywords)
    sim2        = sim.copy()
    sim2[np.arange(len(sim2)), best_idx] = -1
    second_idx  = sim2.argmax(axis=1)

    area_names = [a["name"] for a in RESEARCH_AREAS]

    df["research_area"]       = [
        area_names[i] if s >= threshold else "Unclassified / General Methods"
        for i, s in zip(best_idx, best_score)
    ]
    df["research_area_score"] = best_score.round(4)
    df["research_area_2"]     = [area_names[i] for i in second_idx]

    classified = (df["research_area"] != "Unclassified / General Methods").sum()
    print(f"    â†’ {classified}/{len(df)} keywords classified into a research area")
    print(f"    â†’ {len(df)-classified} below threshold â†’ 'Unclassified / General Methods'")
    print()
    print("    Research area keyword counts:")
    for area, cnt in df["research_area"].value_counts().items():
        bar = "â–ˆ" * min(40, cnt // max(1, len(df) // 200))
        print(f"      {cnt:>5}  {bar}  {area}")

    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. SUB-TOPIC CLUSTERING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _estimate_k(n: int) -> int:
    return max(3, min(60, n // 8))


def cluster_keywords(df: pd.DataFrame, kw_emb: np.ndarray,
                     min_cluster_size: int) -> pd.DataFrame:
    """
    Cluster keywords into fine-grained sub-topics.
    This is secondary to research area mapping â€” it reveals themes WITHIN areas,
    e.g. within Oncology: "HER2 breast cancer", "KRAS colorectal", "PD-L1 NSCLC".
    """
    print("\n[4/5] Clustering into sub-topic groups...")

    from sklearn.decomposition import TruncatedSVD
    from sklearn.cluster import AgglomerativeClustering, KMeans
    from sklearn.manifold import TSNE
    from sklearn.preprocessing import normalize
    from sklearn.metrics import pairwise_distances_argmin_min

    n      = len(df)
    n_comp = min(50, kw_emb.shape[1] - 1, n - 1)

    svd     = TruncatedSVD(n_components=n_comp, random_state=42)
    reduced = normalize(svd.fit_transform(kw_emb))

    k = _estimate_k(n)
    print(f"    â†’ k={k} sub-topic clusters for {n} keywords")

    if n <= 5000:
        labels = AgglomerativeClustering(
            n_clusters=k, metric="cosine", linkage="average"
        ).fit_predict(reduced)
    else:
        labels = KMeans(
            n_clusters=k, random_state=42, n_init="auto"
        ).fit_predict(reduced)

    # Merge tiny clusters
    counts    = pd.Series(labels).value_counts()
    small_ids = counts[counts < min_cluster_size].index.tolist()
    if small_ids:
        vm = ~np.isin(labels, small_ids)
        sm = np.isin(labels, small_ids)
        if vm.sum() > 0 and sm.sum() > 0:
            nearest, _ = pairwise_distances_argmin_min(
                reduced[sm], reduced[vm], metric="cosine"
            )
            labels = labels.copy()
            labels[sm] = labels[vm][nearest]
        print(f"    â†’ Merged {len(small_ids)} tiny cluster(s)")

    # Label each cluster by keyword closest to centroid
    label_map = {}
    for cid in np.unique(labels):
        mask     = labels == cid
        embs     = reduced[mask]
        centroid = embs.mean(axis=0)
        closest  = df.loc[mask, "keyword"].iloc[(embs @ centroid).argmax()]
        label_map[cid] = closest

    df["cluster_id"]    = labels
    df["cluster_label"] = [label_map[c] for c in labels]
    print(f"    â†’ {len(label_map)} sub-topic clusters")

    # t-SNE for visualization
    print("    â†’ Running t-SNE...")
    perp = min(30, max(5, n // 10))
    tsne = TSNE(n_components=2, perplexity=perp,
                learning_rate="auto", init="pca", random_state=42)
    xy   = tsne.fit_transform(reduced)
    df["tsne_x"] = xy[:, 0]
    df["tsne_y"] = xy[:, 1]

    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. SCORE & RECOMMEND
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def score_and_recommend(df: pd.DataFrame, top_n: int) -> tuple:
    """
    Aggregate keyword-level assignments into research area scores.

    Opportunity Score = 70% keyword count (breadth) + 30% avg similarity (depth)

    Sub-topics show the most common cluster labels within each area,
    giving content creators a starting point for article angles.
    """
    print("\n[5/5] Scoring research areas...")

    work = df[df["research_area"] != "Unclassified / General Methods"].copy()

    area_df = (
        work.groupby("research_area")
        .agg(
            keyword_count   = ("keyword", "count"),
            avg_similarity  = ("research_area_score", "mean"),
            sample_keywords = ("keyword", lambda x: " | ".join(list(x)[:10])),
            sub_topics      = ("cluster_label", lambda x: " Â· ".join(
                                x.value_counts().head(5).index.tolist()))
        )
        .reset_index()
    )

    max_count = area_df["keyword_count"].max()
    area_df["count_score"]       = area_df["keyword_count"] / max_count
    area_df["opportunity_score"] = (
        area_df["count_score"]   * 0.70 +
        area_df["avg_similarity"] * 0.30
    ).round(3)

    def tier(s):
        if s >= 0.55: return "ğŸ”´ High Priority"
        if s >= 0.30: return "ğŸŸ¡ Medium Priority"
        return                "ğŸŸ¢ Explore / Monitor"

    area_df["priority"] = area_df["opportunity_score"].apply(tier)

    recs = (
        area_df
        .sort_values("opportunity_score", ascending=False)
        .head(top_n)
        .reset_index(drop=True)
    )
    recs.index     += 1
    recs.index.name = "rank"

    print(f"    â†’ {len(area_df)} research areas scored")
    return area_df, recs


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. HTML REPORT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_report(df: pd.DataFrame, recs: pd.DataFrame, output_dir: str):
    print("\n    â†’ Generating HTML report...")

    try:
        import plotly.express as px
        import plotly.io as pio

        fig = px.scatter(
            df, x="tsne_x", y="tsne_y",
            color="research_area",
            hover_data=["keyword", "cluster_label", "research_area_score"],
            title="Keyword Map â€” Coloured by Research Area",
            labels={"tsne_x": "t-SNE 1", "tsne_y": "t-SNE 2",
                    "research_area": "Research Area"},
            height=750, template="plotly_white"
        )
        fig.update_traces(marker=dict(size=5, opacity=0.75))
        fig.update_layout(legend=dict(orientation="v", x=1.02, y=1))
        scatter_html = pio.to_html(fig, full_html=False, include_plotlyjs="cdn")
    except ImportError:
        scatter_html = "<p><em>pip install plotly for interactive chart</em></p>"

    rec_rows = ""
    for rank, row in recs.iterrows():
        rec_rows += f"""
        <tr>
          <td style='text-align:center;font-weight:700'>{rank}</td>
          <td><strong>{row['research_area']}</strong></td>
          <td style='text-align:center'>{row['keyword_count']}</td>
          <td style='text-align:center'>{row['avg_similarity']:.3f}</td>
          <td style='text-align:center'>{row['opportunity_score']:.3f}</td>
          <td>{row['priority']}</td>
          <td style='font-size:0.82em;color:#444'>{row.get('sub_topics','')}</td>
          <td style='font-size:0.82em;color:#777'>{row['sample_keywords']}</td>
        </tr>"""

    unclass     = df[df["research_area"] == "Unclassified / General Methods"]
    unclass_kws = " &nbsp;Â·&nbsp; ".join(unclass["keyword"].head(50).tolist())
    unclass_html = f"""
    <h2>âšª Unclassified / General Methods ({len(unclass)} keywords)</h2>
    <div style='background:white;border-radius:10px;padding:16px;
                box-shadow:0 2px 8px rgba(0,0,0,.08);font-size:0.86em;color:#555;
                line-height:1.8'>
      {unclass_kws}{'&nbsp;Â·&nbsp;<em>...and more</em>' if len(unclass)>50 else ''}
    </div>""" if len(unclass) else ""

    n_areas   = (df["research_area"] != "Unclassified / General Methods").sum()
    n_areas_u = df["research_area"].nunique() - (1 if len(unclass) else 0)

    html = f"""<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Life Science Research Area Report</title>
  <style>
    body   {{ font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',sans-serif;
             margin:0;padding:24px 44px;background:#f0f4f8;color:#212529; }}
    h1     {{ color:#0d1b2a;border-bottom:3px solid #0077b6;padding-bottom:10px; }}
    h2     {{ color:#0077b6;margin-top:36px; }}
    .stats {{ display:flex;gap:16px;flex-wrap:wrap;margin:20px 0; }}
    .card  {{ background:white;border-radius:10px;padding:14px 22px;
             box-shadow:0 2px 8px rgba(0,0,0,.08);min-width:130px; }}
    .card .num {{ font-size:1.9em;font-weight:700;color:#0077b6; }}
    .card .lbl {{ font-size:0.82em;color:#6c757d;margin-top:3px; }}
    table  {{ width:100%;border-collapse:collapse;background:white;
             border-radius:10px;overflow:hidden;
             box-shadow:0 2px 8px rgba(0,0,0,.08); }}
    th     {{ background:#0077b6;color:white;padding:11px 10px;
             text-align:left;font-size:0.86em; }}
    td     {{ padding:10px;border-bottom:1px solid #e9ecef;font-size:0.88em; }}
    tr:hover td {{ background:#e8f4fd; }}
    .plot  {{ background:white;border-radius:10px;padding:16px;
             box-shadow:0 2px 8px rgba(0,0,0,.08);margin:16px 0; }}
    .note  {{ background:#d1ecf1;border-left:4px solid #0077b6;
             padding:12px 16px;border-radius:4px;margin:16px 0;font-size:0.88em; }}
  </style>
</head>
<body>
  <h1>ğŸ”¬ Life Science Research Area Recommendations</h1>

  <div class="stats">
    <div class="card"><div class="num">{len(df)}</div><div class="lbl">Total Keywords</div></div>
    <div class="card"><div class="num">{n_areas_u}</div><div class="lbl">Research Areas Hit</div></div>
    <div class="card"><div class="num">{n_areas}</div><div class="lbl">Classified Keywords</div></div>
    <div class="card"><div class="num">{len(unclass)}</div><div class="lbl">Unclassified</div></div>
    <div class="card"><div class="num">{df['cluster_id'].nunique()}</div><div class="lbl">Sub-topic Clusters</div></div>
  </div>

  <div class="note">
    <strong>How to read this:</strong> Research areas come from a predefined life science taxonomy
    ({len(RESEARCH_AREAS)} areas). Every keyword is matched via semantic similarity â€” output is
    always a meaningful disease/research area, never a lab technique.
    <strong>Opportunity Score</strong> = 70% keyword count + 30% avg similarity strength.
    <strong>Sub-topics</strong> show the key themes within each area to guide content angles.
  </div>

  <h2>ğŸ“Š Keyword Map by Research Area</h2>
  <div class="plot">{scatter_html}</div>

  <h2>ğŸ¯ Research Area Recommendations</h2>
  <table>
    <thead>
      <tr>
        <th>#</th><th>Research Area</th><th>Keywords</th>
        <th>Avg Similarity</th><th>Opp. Score</th><th>Priority</th>
        <th>Key Sub-topics</th><th>Sample Keywords</th>
      </tr>
    </thead>
    <tbody>{rec_rows}</tbody>
  </table>

  {unclass_html}

  <p style="margin-top:40px;color:#aaa;font-size:0.78em">
    Model: all-MiniLM-L6-v2 &nbsp;|&nbsp;
    {len(RESEARCH_AREAS)} taxonomy areas &nbsp;|&nbsp;
    Agglomerative clustering + t-SNE
  </p>
</body>
</html>"""

    path = os.path.join(output_dir, "report.html")
    with open(path, "w", encoding="utf-8") as f:
        f.write(html)
    print(f"    â†’ Report saved: {path}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    args = parse_args()
    os.makedirs(args.output, exist_ok=True)

    df                  = load_keywords(args.input, args.col)
    kw_emb, area_emb   = embed_all(df)
    df                  = map_to_research_areas(df, kw_emb, area_emb, args.threshold)
    df                  = cluster_keywords(df, kw_emb, args.min_cluster_size)
    area_df, recs       = score_and_recommend(df, args.top_n)

    clusters_path = os.path.join(args.output, "clusters.csv")
    recs_path     = os.path.join(args.output, "recommendations.csv")

    df.drop(columns=["tsne_x", "tsne_y"], errors="ignore").to_csv(clusters_path, index=False)
    recs.to_csv(recs_path)
    generate_report(df, recs, args.output)

    print("\n" + "â•"*62)
    print("âœ…  Pipeline complete!")
    print(f"   clusters.csv        â†’ {clusters_path}")
    print(f"   recommendations.csv â†’ {recs_path}")
    print(f"   report.html         â†’ {os.path.join(args.output, 'report.html')}")
    print("â•"*62)
    print("\nğŸ“‹  Research Area Recommendations:\n")
    print(recs[["research_area", "keyword_count", "avg_similarity",
                "opportunity_score", "priority"]].to_string())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPTIONAL: Plug in GSC / SEMrush search volume
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. Before map_to_research_areas(), merge your volume data:
#      vol = pd.read_csv("volumes.csv")   # columns: keyword, volume
#      df  = df.merge(vol, on="keyword", how="left")
#      df["volume"] = df["volume"].fillna(0)
#
# 2. In score_and_recommend(), add to the groupby agg:
#      total_volume = ("volume", "sum")
#
# 3. Replace count_score with:
#      area_df["count_score"] = area_df["total_volume"] / area_df["total_volume"].max()
#
# This makes Opportunity Score reflect real search demand rather than keyword count.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    main()
